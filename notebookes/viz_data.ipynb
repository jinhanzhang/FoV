{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, argparse, sys, os, errno\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#sns.set()\n",
    "#sns.set_style('whitegrid')\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy\n",
    "import sklearn\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.path.append('/scratch/xc1490/projects/tmp/python_packages')\n",
    "sys.path.append('/scratch/xc1490/projects/tmp/python_packages/') #pip install --target=/home/xc1490/home/projects/tmp/python_packages package_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from ast import arg, parse\n",
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import wandb\n",
    "wandb.__version__\n",
    "from utils import *\n",
    "# from dataloader import\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='FoV')\n",
    "# basic config\n",
    "parser.add_argument('--model', type=str, required=False, default='XGBOOST',\n",
    "                    help='model name, options: [Autoformer, Transformer, iTransformer, Reformer, TimesNet, PatchTST]')\n",
    "parser.add_argument('--root_path', type=str, default=f'{os.getcwd()}', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default='/processed_data', help='data file')\n",
    "parser.add_argument('--hist_time', type=int, default=2, help='history data time')\n",
    "parser.add_argument('--pred_time', type=int, default=2, help='prediction data time')\n",
    "parser.add_argument('--batch_size', type=int, default=16, help='batch size')\n",
    "parser.add_argument('--feature_names', type=str, default='XYZ_FEATURE_NAMES', help='[DEFAULT_FEATURE_NAMES, XYZ_FEATURE_NAMES, ONE_FEATURE, SC_FEATURE_NAMES, RPY_FEATURE_NAMES, ANGLE_FEATURE_NAMES]')\n",
    "parser.add_argument('--load_model', type=bool, default=False, help='load model')\n",
    "parser.add_argument('--use_wandb', type=bool, default=False, help='use wandb for logging')\n",
    "# transformer config\n",
    "parser.add_argument('--n_heads', type=int, default=3, help='number of heads')\n",
    "parser.add_argument('--head_dim', type=int, default=3, help='head dimension')\n",
    "parser.add_argument('--dim_val', type=int, default=9, help='embedding dimension')\n",
    "parser.add_argument('--n_decoder_layers', type=int, default=2, help='number of decoder layers')\n",
    "parser.add_argument('--n_encoder_layers', type=int, default=2, help='number of encoder layers')\n",
    "parser.add_argument('--pe_mode', type=str, default='standard', help='positional encoding mode')\n",
    "args = parser.parse_args(args=[])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed = 2024\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "id = datetime.now().strftime(\"%m/%d/%Y-%H:%M:%S\")\n",
    "saved_path = f'saved_results/{id}'\n",
    "if not os.path.exists(saved_path):\n",
    "    os.makedirs(saved_path)\n",
    "# parse augments\n",
    "\n",
    "\n",
    "# config\n",
    "PROJECT_PATH = args.root_path\n",
    "FRAME_RATE = 60 # 60 frames/sec\n",
    "MAX_HISTORY_TIME = 10\n",
    "MAX_PREDICTION_TIME = 10\n",
    "HISTORY_TIME = args.hist_time\n",
    "PREDICTION_TIME = args.pred_time\n",
    "HISTORY_LENGTH = HISTORY_TIME*FRAME_RATE\n",
    "PREDICTION_LENGTH = PREDICTION_TIME*FRAME_RATE\n",
    "MAX_HISTORY_LENGTH = MAX_HISTORY_TIME*FRAME_RATE\n",
    "MAX_PREDICTION_LENGTH = MAX_PREDICTION_TIME*FRAME_RATE\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device: \", DEVICE)\n",
    "TOTAL_FEATURE_NAMES = ['head_x','head_y','head_z','head_r_sin','head_r_cos','head_p_sin','head_p_cos','head_y_sin',\\\n",
    "'head_y_cos','head_rx','head_ry','head_rz']\n",
    "DEFAULT_FEATURE_NAMES = ['head_x','head_y','head_z','head_r_sin','head_r_cos','head_p_sin','head_p_cos','head_y_sin',\\\n",
    "'head_y_cos']\n",
    "XYZ_FEATURE_NAMES = ['head_x', 'head_y', 'head_z']\n",
    "ONE_FEATURE = ['head_x']\n",
    "SC_FEATURE_NAMES = ['head_r_sin','head_r_cos','head_p_sin','head_p_cos','head_y_sin','head_y_cos']\n",
    "RPY_FEATURE_NAMES = ['head_rx','head_ry','head_rz']\n",
    "ANGLE_FEATURE_NAMES = ['head_r_cos','head_p_sin','head_p_cos','head_y_sin','head_y_cos','head_rx','head_ry','head_rz']\n",
    "FEATURE_NAMES = eval(args.feature_names)\n",
    "FEATURE_INDEX = [TOTAL_FEATURE_NAMES.index(x) for x in FEATURE_NAMES]\n",
    "DEFAULT_FEATURE_SIZE = len(DEFAULT_FEATURE_NAMES)\n",
    "FEATURE_SIZE = len(FEATURE_NAMES)\n",
    "BATCH_SIZE = args.batch_size\n",
    "LOAD_MODEL = args.load_model\n",
    "\n",
    "# load data\n",
    "processed_data_path = f'{PROJECT_PATH}/processed_data'\n",
    "x_train = np.loadtxt(f'{processed_data_path}/x_train_{HISTORY_TIME}_{PREDICTION_TIME}.csv', dtype='float32', delimiter=',').reshape((-1,HISTORY_LENGTH,DEFAULT_FEATURE_SIZE))\n",
    "y_train = np.loadtxt(f'{processed_data_path}/y_train_{HISTORY_TIME}_{PREDICTION_TIME}.csv', dtype='float32', delimiter=',').reshape((-1,PREDICTION_LENGTH,DEFAULT_FEATURE_SIZE))\n",
    "x_val = np.loadtxt(f'{processed_data_path}/x_val_{HISTORY_TIME}_{PREDICTION_TIME}.csv', dtype='float32', delimiter=',').reshape((-1,HISTORY_LENGTH,DEFAULT_FEATURE_SIZE))\n",
    "y_val = np.loadtxt(f'{processed_data_path}/y_val_{HISTORY_TIME}_{PREDICTION_TIME}.csv', dtype='float32', delimiter=',').reshape((-1,PREDICTION_LENGTH,DEFAULT_FEATURE_SIZE))\n",
    "x_test = np.loadtxt(f'{processed_data_path}/x_test_{HISTORY_TIME}_{PREDICTION_TIME}.csv', dtype='float32', delimiter=',').reshape((-1,HISTORY_LENGTH,DEFAULT_FEATURE_SIZE))\n",
    "y_test = np.loadtxt(f'{processed_data_path}/y_test_{HISTORY_TIME}_{PREDICTION_TIME}.csv', dtype='float32', delimiter=',').reshape((-1,PREDICTION_LENGTH,DEFAULT_FEATURE_SIZE))\n",
    "mean_std = np.loadtxt(f'{processed_data_path}/xyz_mean_std_{HISTORY_TIME}_{PREDICTION_TIME}.csv', dtype='float32', delimiter=',').reshape((3, -1))\n",
    "\n",
    "# create dataset and dataloader\n",
    "feature_names = FEATURE_NAMES\n",
    "feature_idx = FEATURE_INDEX\n",
    "x_train = x_train[:,:,feature_idx]\n",
    "y_train = y_train[:,:,feature_idx]\n",
    "x_val = x_val[:,:,feature_idx]\n",
    "y_val = y_val[:,:,feature_idx]\n",
    "x_test = x_test[:,:,feature_idx]\n",
    "y_test = y_test[:,:,feature_idx]\n",
    "train_data = FoVDataset(x_train, y_train, feature_idx)\n",
    "val_data = FoVDataset(x_val, y_val, feature_idx)\n",
    "test_data = FoVDataset(x_test, y_test, feature_idx)\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "#training hyperparams\n",
    "in_seq_len = HISTORY_LENGTH\n",
    "out_seq_len = PREDICTION_LENGTH\n",
    "feature_size = FEATURE_SIZE\n",
    "lr = 0.005\n",
    "tf_rate = 0.5\n",
    "epochs = 200\n",
    "batch_size = BATCH_SIZE\n",
    "n_batches = len(train_dataloader)\n",
    "use_wandb = args.use_wandb\n",
    "# init model\n",
    "model_name = args.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, input_temporal_dim, input_feature_dim = x_train.shape\n",
    "bs, output_temporal_dim, output_feature_dim = y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_nums = 10\n",
    "for batch in tqdm(range(bs // sample_nums)):\n",
    "    start = batch * sample_nums\n",
    "    end = min(batch * sample_nums+sample_nums,bs)\n",
    "   \n",
    "    fig, ax = plt.subplots(sample_nums,3,figsize=(20,4*sample_nums))\n",
    "    for j, sample_id in enumerate(np.arange(start, end)):\n",
    "        for i in range(3):  \n",
    "            ax[j, i ].plot(np.arange(0,input_temporal_dim), x_train[sample_id,:,i ],label='input')\n",
    "            ax[j, i ].plot(np.arange(input_temporal_dim, input_temporal_dim+output_temporal_dim),y_train[sample_id,:,i ],label='target')\n",
    "            ax[j, i ].legend( )\n",
    "            ax[j, i ].set_title('sample: {}, feature: {}'.format(sample_id,['x','y','z'][i]))\n",
    "    fig.savefig('processed_data/viz/figures/train/{}_{}.png'.format(start,end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mkdir -p processed_data/viz/figures/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
